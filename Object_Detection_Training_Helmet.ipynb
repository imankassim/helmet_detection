{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object Detection Training: Helmet",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imankassim/helmet_detection/blob/master/Object_Detection_Training_Helmet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmdLTVqlyJgs",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Download the project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVyydtflf73m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPJMmLKwx0c5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e61b3471-410a-4271-96c0-8d8f97a4b9fc"
      },
      "source": [
        "!wget -c 'https://helmet-detection-computer-vision.s3.eu-west-2.amazonaws.com/data.zip'\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-07 16:30:27--  https://helmet-detection-computer-vision.s3.eu-west-2.amazonaws.com/data.zip\n",
            "Resolving helmet-detection-computer-vision.s3.eu-west-2.amazonaws.com (helmet-detection-computer-vision.s3.eu-west-2.amazonaws.com)... 52.95.150.38\n",
            "Connecting to helmet-detection-computer-vision.s3.eu-west-2.amazonaws.com (helmet-detection-computer-vision.s3.eu-west-2.amazonaws.com)|52.95.150.38|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 496206 (485K) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "\rdata.zip              0%[                    ]       0  --.-KB/s               \rdata.zip            100%[===================>] 484.58K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-09-07 16:30:28 (11.3 MB/s) - ‘data.zip’ saved [496206/496206]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7BYyX-hNGfG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "95ca2f59-48a4-434c-cd3d-c618f27ec6a9"
      },
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/coco/\n",
            "   creating: data/coco/annotations/\n",
            "  inflating: data/coco/annotations/instances_test2017.json  \n",
            "  inflating: data/coco/annotations/instances_train2017.json  \n",
            "  inflating: data/coco/annotations/instances_val2017.json  \n",
            "  inflating: data/coco/labelme2coco.py  \n",
            "   creating: data/coco/test2017/\n",
            "  inflating: data/coco/test2017/25.jpg  \n",
            "  inflating: data/coco/test2017/25.json  \n",
            "  inflating: data/coco/test2017/26.jpg  \n",
            "  inflating: data/coco/test2017/26.json  \n",
            "  inflating: data/coco/test2017/27.jpg  \n",
            "  inflating: data/coco/test2017/27.json  \n",
            "  inflating: data/coco/test2017/28.jpg  \n",
            "  inflating: data/coco/test2017/28.json  \n",
            "  inflating: data/coco/test2017/29.jpg  \n",
            "  inflating: data/coco/test2017/29.json  \n",
            "   creating: data/coco/train2017/\n",
            "  inflating: data/coco/train2017/0.jpg  \n",
            "  inflating: data/coco/train2017/0.json  \n",
            "  inflating: data/coco/train2017/1.jpg  \n",
            "  inflating: data/coco/train2017/1.json  \n",
            "  inflating: data/coco/train2017/10.jpg  \n",
            "  inflating: data/coco/train2017/10.json  \n",
            "  inflating: data/coco/train2017/11.jpg  \n",
            "  inflating: data/coco/train2017/11.json  \n",
            "  inflating: data/coco/train2017/12.jpg  \n",
            "  inflating: data/coco/train2017/12.json  \n",
            "  inflating: data/coco/train2017/13.jpg  \n",
            "  inflating: data/coco/train2017/13.json  \n",
            "  inflating: data/coco/train2017/14.jpg  \n",
            "  inflating: data/coco/train2017/14.json  \n",
            "  inflating: data/coco/train2017/15.jpg  \n",
            "  inflating: data/coco/train2017/15.json  \n",
            "  inflating: data/coco/train2017/16.jpg  \n",
            "  inflating: data/coco/train2017/16.json  \n",
            "  inflating: data/coco/train2017/17.jpg  \n",
            "  inflating: data/coco/train2017/17.json  \n",
            "  inflating: data/coco/train2017/18.jpg  \n",
            "  inflating: data/coco/train2017/18.json  \n",
            "  inflating: data/coco/train2017/19.jpg  \n",
            "  inflating: data/coco/train2017/19.json  \n",
            "  inflating: data/coco/train2017/2.jpg  \n",
            "  inflating: data/coco/train2017/2.json  \n",
            "  inflating: data/coco/train2017/3.jpg  \n",
            "  inflating: data/coco/train2017/3.json  \n",
            "  inflating: data/coco/train2017/4.jpg  \n",
            "  inflating: data/coco/train2017/4.json  \n",
            "  inflating: data/coco/train2017/5.jpg  \n",
            "  inflating: data/coco/train2017/5.json  \n",
            "  inflating: data/coco/train2017/6.jpg  \n",
            "  inflating: data/coco/train2017/6.json  \n",
            "  inflating: data/coco/train2017/7.jpg  \n",
            "  inflating: data/coco/train2017/7.json  \n",
            "  inflating: data/coco/train2017/8.jpg  \n",
            "  inflating: data/coco/train2017/8.json  \n",
            "  inflating: data/coco/train2017/9.jpg  \n",
            "  inflating: data/coco/train2017/9.json  \n",
            "   creating: data/coco/val2017/\n",
            "  inflating: data/coco/val2017/20.jpg  \n",
            "  inflating: data/coco/val2017/20.json  \n",
            "  inflating: data/coco/val2017/21.jpg  \n",
            "  inflating: data/coco/val2017/21.json  \n",
            "  inflating: data/coco/val2017/22.jpg  \n",
            "  inflating: data/coco/val2017/22.json  \n",
            "  inflating: data/coco/val2017/23.jpg  \n",
            "  inflating: data/coco/val2017/23.json  \n",
            "  inflating: data/coco/val2017/24.jpg  \n",
            "  inflating: data/coco/val2017/24.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1sr9NNOyRGL",
        "colab_type": "text"
      },
      "source": [
        "### Change directory into the project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMv4A_OAyBE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fa901c3e-f84f-4f7f-88ca-7f9c8428256f"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIuLRJtUyjyt",
        "colab_type": "text"
      },
      "source": [
        "### Clone the MMDetection project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiADxvc2yOQ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f136bf03-de9b-4579-8268-b6319b19d413"
      },
      "source": [
        "!git clone https://github.com/open-mmlab/mmdetection.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'mmdetection'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 13137 (delta 1), reused 1 (delta 0), pack-reused 13128\u001b[K\n",
            "Receiving objects: 100% (13137/13137), 13.71 MiB | 11.23 MiB/s, done.\n",
            "Resolving deltas: 100% (8873/8873), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB1Q8a2Hy4Z_",
        "colab_type": "text"
      },
      "source": [
        "### Move the data into the mmdetection directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l22YmA-DyXMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mv data/ mmdetection/"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMnbTvJGRxWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dd64f58b-7f10-42a7-97c2-1b6c0227a463"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Hg5Ufsyy9NQ",
        "colab_type": "text"
      },
      "source": [
        "### Change into the mmdetection directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6VmoVknyZAe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7382e6c6-d75a-4e23-cb6b-0ca6990fc197"
      },
      "source": [
        "cd mmdetection/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/mmdetection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJncBEKJzJSm",
        "colab_type": "text"
      },
      "source": [
        "### Build and setup MMDetection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX1gccwsy0B1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb3c0780-7c8d-4baa-9475-c70d5f8a2770"
      },
      "source": [
        "!sudo pip install -r requirements/build.txt\n",
        "!sudo pip install \"git+https://github.com/open-mmlab/cocoapi.git#subdirectory=pycocotools\"\n",
        "!sudo pip install -v -e .\n",
        "!sudo pip install mmcv-full"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from -r requirements/build.txt (line 2)) (0.29.21)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements/build.txt (line 3)) (1.18.5)\n",
            "Collecting git+https://github.com/open-mmlab/cocoapi.git#subdirectory=pycocotools\n",
            "  Cloning https://github.com/open-mmlab/cocoapi.git to /tmp/pip-req-build-ljlmew2u\n",
            "  Running command git clone -q https://github.com/open-mmlab/cocoapi.git /tmp/pip-req-build-ljlmew2u\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==12.0) (49.6.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools==12.0) (0.29.21)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==12.0) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==12.0) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==12.0) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==12.0) (1.18.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==12.0) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==12.0) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==12.0) (1.15.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-12.0-cp36-cp36m-linux_x86_64.whl size=266753 sha256=ec2fbece02cb6b23780852bb8fc2c2160a1c2e85c1350fa6d129528799fc6cd2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wwk6ofhk/wheels/cd/f6/de/018ccc2d175046c612e93b42a169cd1ab7563d61581cfba8df\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Found existing installation: pycocotools 2.0.1\n",
            "    Uninstalling pycocotools-2.0.1:\n",
            "      Successfully uninstalled pycocotools-2.0.1\n",
            "Successfully installed pycocotools-12.0\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-jyiybrr5\n",
            "Created temporary directory: /tmp/pip-req-tracker-vabvx3lr\n",
            "Created requirements tracker '/tmp/pip-req-tracker-vabvx3lr'\n",
            "Created temporary directory: /tmp/pip-install-mt5sqpxy\n",
            "Obtaining file:///content/mmdetection\n",
            "  Added file:///content/mmdetection to build tracker '/tmp/pip-req-tracker-vabvx3lr'\n",
            "    Running setup.py (path:/content/mmdetection/setup.py) egg_info for package from file:///content/mmdetection\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating mmdet.egg-info\n",
            "    writing mmdet.egg-info/PKG-INFO\n",
            "    writing dependency_links to mmdet.egg-info/dependency_links.txt\n",
            "    writing requirements to mmdet.egg-info/requires.txt\n",
            "    writing top-level names to mmdet.egg-info/top_level.txt\n",
            "    writing manifest file 'mmdet.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'mmdet.egg-info/SOURCES.txt'\n",
            "  Source in /content/mmdetection has version 2.4.0, which satisfies requirement mmdet==2.4.0 from file:///content/mmdetection\n",
            "  Removed mmdet==2.4.0 from file:///content/mmdetection from build tracker '/tmp/pip-req-tracker-vabvx3lr'\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from mmdet==2.4.0) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mmdet==2.4.0) (1.18.5)\n",
            "Requirement already satisfied: pycocotools@ git+https://github.com/open-mmlab/cocoapi.git#subdirectory=pycocotools from git+https://github.com/open-mmlab/cocoapi.git#subdirectory=pycocotools in /usr/local/lib/python3.6/dist-packages (from mmdet==2.4.0) (12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from mmdet==2.4.0) (1.15.0)\n",
            "1 location(s) to search for versions of terminaltables:\n",
            "* https://pypi.org/simple/terminaltables/\n",
            "Getting page https://pypi.org/simple/terminaltables/\n",
            "Found index url https://pypi.org/simple\n",
            "Looking up \"https://pypi.org/simple/terminaltables/\" in the cache\n",
            "Request header has \"max_age\" as 0, cache bypassed\n",
            "Starting new HTTPS connection (1): pypi.org:443\n",
            "https://pypi.org:443 \"GET /simple/terminaltables/ HTTP/1.1\" 200 1186\n",
            "Updating cache with response from \"https://pypi.org/simple/terminaltables/\"\n",
            "Caching due to etag\n",
            "Analyzing links from page https://pypi.org/simple/terminaltables/\n",
            "  Found link https://files.pythonhosted.org/packages/ec/82/6390ba7f110622d27b02451aaa294dc4b3133b7661e464db9a116e977324/terminaltables-1.0.0.tar.gz#sha256=4c909a5ee4a3d028b2c977d996f8b8cd9724ce8e4d9d834d65e78a98f7965b54 (from https://pypi.org/simple/terminaltables/), version: 1.0.0\n",
            "  Found link https://files.pythonhosted.org/packages/97/65/858bc3ea6cc60edc959ce427a94227932b5d9a95b0bce82f16071419885c/terminaltables-1.0.1.tar.gz#sha256=5548ac567d38d6ac88a5e0fec2d95f646249f37e1ef8fd2d17f8fcaefc6cf592 (from https://pypi.org/simple/terminaltables/), version: 1.0.1\n",
            "  Found link https://files.pythonhosted.org/packages/82/42/3f1140f6e538582fd514c765244662cca60885048cf610e7d00eaee8aeb1/terminaltables-1.0.2.tar.gz#sha256=cf97dd019af975cc64aa69aca435a43b0cffabb88df6f337c6b48de600c19f8e (from https://pypi.org/simple/terminaltables/), version: 1.0.2\n",
            "  Found link https://files.pythonhosted.org/packages/80/07/5663569dfd8fa4e4fa3cb645b70f4972e3d79d056b71da12df174668c145/terminaltables-1.1.0.tar.gz#sha256=94a15e1a295265d130de67e9c2efef9e1cad1e64dd6ae0b80882076581605f8c (from https://pypi.org/simple/terminaltables/), version: 1.1.0\n",
            "  Found link https://files.pythonhosted.org/packages/0c/4a/9b80642ac2463908fe77c9dbe138c56902fbf5a5a95d07203c131ec9ba90/terminaltables-1.1.1.tar.gz#sha256=b02c516d6d521ce0fe6e2a2753268e86547bbccab6bfa7e269a0f51766283fab (from https://pypi.org/simple/terminaltables/), version: 1.1.1\n",
            "  Found link https://files.pythonhosted.org/packages/a8/65/f9c6bcfb1f81acdfcd1f8d633c6752cfdcc04b5fade7638a2a8dc7a720de/terminaltables-1.2.0.tar.gz#sha256=fff4aa62f296038d1526a91856f0b3de1e3bce31cfd1c5148cc3f795c1d396bf (from https://pypi.org/simple/terminaltables/), version: 1.2.0\n",
            "  Found link https://files.pythonhosted.org/packages/3d/17/14aa6521b337be46c51dd7b31e7e617801e9f8db7f48583c767c02e0e72a/terminaltables-1.2.1.tar.gz#sha256=cf5f0fb6c6c3070d7af73537ded030858c122f253c87e7221f9a6da3782ce787 (from https://pypi.org/simple/terminaltables/), version: 1.2.1\n",
            "  Found link https://files.pythonhosted.org/packages/d0/8e/9403573ff8aebc09ee0aacd57885050f74bd9f48a85c0735d33cacfa2469/terminaltables-2.0.0.tar.gz#sha256=2e0a6688071f2a881f8fa4455a362457dcd2317e374609f1a09baffa998e7492 (from https://pypi.org/simple/terminaltables/), version: 2.0.0\n",
            "  Found link https://files.pythonhosted.org/packages/10/da/9bbb21c1c2f9be4df2056b00b569689b9ece538ef39bf8db34be25f9e850/terminaltables-2.1.0.tar.gz#sha256=33b60f027964214f4ff5821f43958d03add81784f7c183d86a7ee8f010350cf5 (from https://pypi.org/simple/terminaltables/), version: 2.1.0\n",
            "  Found link https://files.pythonhosted.org/packages/58/c9/f0c174c4e828365df3593c66ac32474cd994a8ec36fe19a798261c96c3bc/terminaltables-3.0.0.tar.gz#sha256=bd2504031f09f942a8f221266adc61aee04a0368d5de0dacb7a53e508af6a518 (from https://pypi.org/simple/terminaltables/), version: 3.0.0\n",
            "  Found link https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81 (from https://pypi.org/simple/terminaltables/), version: 3.1.0\n",
            "Given no hashes to check 11 links for project 'terminaltables': discarding no candidates\n",
            "Using version 3.1.0 (newest of versions: 1.0.0, 1.0.1, 1.0.2, 1.1.0, 1.1.1, 1.2.0, 1.2.1, 2.0.0, 2.1.0, 3.0.0, 3.1.0)\n",
            "Collecting terminaltables\n",
            "  Created temporary directory: /tmp/pip-unpack-c9mr81mr\n",
            "  Looking up \"https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\" in the cache\n",
            "  No cache entry available\n",
            "  Starting new HTTPS connection (1): files.pythonhosted.org:443\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz HTTP/1.1\" 200 12478\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "  Ignoring unknown cache-control directive: immutable\n",
            "  Updating cache with response from \"https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\"\n",
            "  Caching due to etag\n",
            "  Added terminaltables from https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81 (from mmdet==2.4.0) to build tracker '/tmp/pip-req-tracker-vabvx3lr'\n",
            "    Running setup.py (path:/tmp/pip-install-mt5sqpxy/terminaltables/setup.py) egg_info for package terminaltables\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating /tmp/pip-install-mt5sqpxy/terminaltables/pip-egg-info/terminaltables.egg-info\n",
            "    writing /tmp/pip-install-mt5sqpxy/terminaltables/pip-egg-info/terminaltables.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-install-mt5sqpxy/terminaltables/pip-egg-info/terminaltables.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-install-mt5sqpxy/terminaltables/pip-egg-info/terminaltables.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-install-mt5sqpxy/terminaltables/pip-egg-info/terminaltables.egg-info/SOURCES.txt'\n",
            "    reading manifest file '/tmp/pip-install-mt5sqpxy/terminaltables/pip-egg-info/terminaltables.egg-info/SOURCES.txt'\n",
            "    writing manifest file '/tmp/pip-install-mt5sqpxy/terminaltables/pip-egg-info/terminaltables.egg-info/SOURCES.txt'\n",
            "  Source in /tmp/pip-install-mt5sqpxy/terminaltables has version 3.1.0, which satisfies requirement terminaltables from https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81 (from mmdet==2.4.0)\n",
            "  Removed terminaltables from https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81 (from mmdet==2.4.0) from build tracker '/tmp/pip-req-tracker-vabvx3lr'\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mmdet==2.4.0) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mmdet==2.4.0) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mmdet==2.4.0) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mmdet==2.4.0) (0.10.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools@ git+https://github.com/open-mmlab/cocoapi.git#subdirectory=pycocotools->mmdet==2.4.0) (0.29.21)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools@ git+https://github.com/open-mmlab/cocoapi.git#subdirectory=pycocotools->mmdet==2.4.0) (49.6.0)\n",
            "Building wheels for collected packages: terminaltables\n",
            "  Created temporary directory: /tmp/pip-wheel-qn64n5un\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-qn64n5un\n",
            "  Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-mt5sqpxy/terminaltables/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-mt5sqpxy/terminaltables/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-qn64n5un --python-tag cp36\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib\n",
            "  creating build/lib/terminaltables\n",
            "  copying terminaltables/width_and_alignment.py -> build/lib/terminaltables\n",
            "  copying terminaltables/__init__.py -> build/lib/terminaltables\n",
            "  copying terminaltables/base_table.py -> build/lib/terminaltables\n",
            "  copying terminaltables/build.py -> build/lib/terminaltables\n",
            "  copying terminaltables/terminal_io.py -> build/lib/terminaltables\n",
            "  copying terminaltables/github_table.py -> build/lib/terminaltables\n",
            "  copying terminaltables/ascii_table.py -> build/lib/terminaltables\n",
            "  copying terminaltables/other_tables.py -> build/lib/terminaltables\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/width_and_alignment.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/__init__.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/base_table.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/build.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/terminal_io.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/github_table.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/ascii_table.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  copying build/lib/terminaltables/other_tables.py -> build/bdist.linux-x86_64/wheel/terminaltables\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  writing terminaltables.egg-info/PKG-INFO\n",
            "  writing dependency_links to terminaltables.egg-info/dependency_links.txt\n",
            "  writing top-level names to terminaltables.egg-info/top_level.txt\n",
            "  reading manifest file 'terminaltables.egg-info/SOURCES.txt'\n",
            "  writing manifest file 'terminaltables.egg-info/SOURCES.txt'\n",
            "  Copying terminaltables.egg-info to build/bdist.linux-x86_64/wheel/terminaltables-3.1.0-py3.6.egg-info\n",
            "  running install_scripts\n",
            "  creating build/bdist.linux-x86_64/wheel/terminaltables-3.1.0.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-qn64n5un/terminaltables-3.1.0-cp36-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'terminaltables/__init__.py'\n",
            "  adding 'terminaltables/ascii_table.py'\n",
            "  adding 'terminaltables/base_table.py'\n",
            "  adding 'terminaltables/build.py'\n",
            "  adding 'terminaltables/github_table.py'\n",
            "  adding 'terminaltables/other_tables.py'\n",
            "  adding 'terminaltables/terminal_io.py'\n",
            "  adding 'terminaltables/width_and_alignment.py'\n",
            "  adding 'terminaltables-3.1.0.dist-info/METADATA'\n",
            "  adding 'terminaltables-3.1.0.dist-info/WHEEL'\n",
            "  adding 'terminaltables-3.1.0.dist-info/top_level.txt'\n",
            "  adding 'terminaltables-3.1.0.dist-info/zip-safe'\n",
            "  adding 'terminaltables-3.1.0.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15356 sha256=77bc7aeff9888281c35d94db88fad52ee376ca8846238549d651635aee92e433\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "  Removing source in /tmp/pip-install-mt5sqpxy/terminaltables\n",
            "Successfully built terminaltables\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "\n",
            "  Running setup.py develop for mmdet\n",
            "    Running command /usr/bin/python3 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/content/mmdetection/setup.py'\"'\"'; __file__='\"'\"'/content/mmdetection/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps\n",
            "    running develop\n",
            "    running egg_info\n",
            "    writing mmdet.egg-info/PKG-INFO\n",
            "    writing dependency_links to mmdet.egg-info/dependency_links.txt\n",
            "    writing requirements to mmdet.egg-info/requires.txt\n",
            "    writing top-level names to mmdet.egg-info/top_level.txt\n",
            "    writing manifest file 'mmdet.egg-info/SOURCES.txt'\n",
            "    running build_ext\n",
            "    Creating /usr/local/lib/python3.6/dist-packages/mmdet.egg-link (link to .)\n",
            "    Adding mmdet 2.4.0 to easy-install.pth file\n",
            "\n",
            "    Installed /content/mmdetection\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/utils/cpp_extension.py:335: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "      warnings.warn(msg.format('we could not find ninja.'))\n",
            "Successfully installed mmdet terminaltables-3.1.0\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-vabvx3lr'\n",
            "Collecting mmcv-full\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/f5/af334f417b10918a1fe7fe66ffc29020abece67e7b57910c084d3f4313f3/mmcv-full-1.1.2.tar.gz (240kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 6.7MB/s \n",
            "\u001b[?25hCollecting addict\n",
            "  Downloading https://files.pythonhosted.org/packages/14/6f/beb258220417c1a0fe11e842f2e012a1be7eeeaa72a1d10ba17a804da367/addict-2.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mmcv-full) (1.18.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mmcv-full) (3.13)\n",
            "Collecting yapf\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/5d/d84677fe852bc5e091739acda444a9b6700ffc6b11a21b00dd244c8caef0/yapf-0.30.0-py2.py3-none-any.whl (190kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 32.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.6/dist-packages (from mmcv-full) (4.1.2.30)\n",
            "Building wheels for collected packages: mmcv-full\n",
            "  Building wheel for mmcv-full (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmcv-full: filename=mmcv_full-1.1.2-cp36-cp36m-linux_x86_64.whl size=16008514 sha256=20636025119f7aeddd3bef90168ddffc135c90fa46441c8b6938a2be2c4f68d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/1b/e5/a291cfee98447e0126133246510d01ac2ba5225aac9c2eac2e\n",
            "Successfully built mmcv-full\n",
            "Installing collected packages: addict, yapf, mmcv-full\n",
            "Successfully installed addict-2.2.1 mmcv-full-1.1.2 yapf-0.30.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4MIB4GD3tRL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "b103cb8f-30e2-4779-b0ee-ba18d1100872"
      },
      "source": [
        "!sudo pip install mmcv==1.1.1"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mmcv==1.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/0f/71adf51180d7afabe790482f1c8f1129ab6b6fcc7bc7c010691ab67c936f/mmcv-1.1.1.tar.gz (239kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 18.6MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 4.7MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 143kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 174kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 184kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 204kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 215kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 235kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.6/dist-packages (from mmcv==1.1.1) (2.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mmcv==1.1.1) (1.18.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mmcv==1.1.1) (3.13)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.6/dist-packages (from mmcv==1.1.1) (0.30.0)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.6/dist-packages (from mmcv==1.1.1) (4.1.2.30)\n",
            "Building wheels for collected packages: mmcv\n",
            "  Building wheel for mmcv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmcv: filename=mmcv-1.1.1-cp36-cp36m-linux_x86_64.whl size=393324 sha256=578e6f590bf2574e730d5cdefa499e27890073069815579593c6af1d246ed3dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/b2/4b/ab2422df0e82dcaa43835609e2fc01b5f454e8f5346a0cb26b\n",
            "Successfully built mmcv\n",
            "Installing collected packages: mmcv\n",
            "  Found existing installation: mmcv 1.0.5\n",
            "    Uninstalling mmcv-1.0.5:\n",
            "      Successfully uninstalled mmcv-1.0.5\n",
            "Successfully installed mmcv-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-72QGGZz-H6",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Setup code structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COo6wROm0O5p",
        "colab_type": "text"
      },
      "source": [
        "### Setup the libraries we need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf_ch3XjzVR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFp6Rip_0YLa",
        "colab_type": "text"
      },
      "source": [
        "### Setup model structure for choosing the file to run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqOklTC50YVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This provides you a link to the file you want to use and the selected model you want to build\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'faster_rcnn_r50_fpn_1x_coco':{\n",
        "        'config_file': 'configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py'\n",
        "    }\n",
        "}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFJd3pq-1f2j",
        "colab_type": "text"
      },
      "source": [
        "### Setup the number of epochs and model structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCv6xoWa1mkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pick the model you want to use\n",
        "\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'faster_rcnn_r50_fpn_1x_coco' \n",
        "\n",
        "# Total training epochs if you want to update the number of training epoch\n",
        "total_epochs = 12\n",
        "\n",
        "# Recommended resize value\n",
        "image_size = (1333, 800)\n",
        "\n",
        "# Name of the config file.\n",
        "config_file = MODELS_CONFIG[selected_model]['config_file']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2BiGWE_1vJh",
        "colab_type": "text"
      },
      "source": [
        "### Edit files to update classes to match our own class names\n",
        "\n",
        "\n",
        "> MMDetection trains using 80 classes, our project only has one class, so we \n",
        "update some files to update class names and number of classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7agUdMy11sv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e88be363-b1f2-4f8d-c7a4-9b7d4a6d8339"
      },
      "source": [
        "# We want to get the classes we are annotating from\n",
        "annotation_path = os.path.join(\"\", \"data/coco/annotations\", \"instances_train2017.json\")\n",
        "json_file = open(annotation_path)\n",
        "coco = json.load(json_file)\n",
        "print(coco[\"categories\"])\n",
        "classes_names = [category[\"name\"] for category in coco[\"categories\"]]\n",
        "print(classes_names)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'supercategory': 'helmet', 'id': 0, 'name': 'helmet'}]\n",
            "['helmet']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MBWE3A12Fzu",
        "colab_type": "text"
      },
      "source": [
        "### Update the \"/mmdet/datasets/coco.py\" file to update the class names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQIQo9dn18g2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "coco_dataset_class_file = \"mmdet/datasets/coco.py\"\n",
        "import re\n",
        "fname = coco_dataset_class_file\n",
        "with open(fname) as f:\n",
        "  s = f.read()\n",
        "  s = re.sub('CLASSES = \\(.*?\\)',\n",
        "               'CLASSES = ({})'.format(\"\".join([\"\\'{}\\',\".format(name) for name in classes_names])), s, flags=re.S)\n",
        "with open(fname, 'w') as f:\n",
        "    f.write(s)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaUzRgx32fgo",
        "colab_type": "text"
      },
      "source": [
        "### Setup the base code from where all its code stems from\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-g_Zmj32PM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_config_fname = 'configs/_base_/models/faster_rcnn_r50_fpn.py'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYeUm4q52ktW",
        "colab_type": "text"
      },
      "source": [
        "### Update the number of classes we are working on in the base file\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UET3OnrV2bYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fname = base_config_fname\n",
        "with open(fname) as f:\n",
        "    s = f.read()\n",
        "    # Update `num_classes` including `background` class.\n",
        "    s = re.sub('num_classes=.*?,',\n",
        "               'num_classes={},'.format(len(classes_names)), s)\n",
        "with open(fname, 'w') as f:\n",
        "    f.write(s)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWhqZs9l2q00",
        "colab_type": "text"
      },
      "source": [
        "### Create helper function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRcp08WH2oAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace_second_occurrence(text, find_this, replace_with):\n",
        "    return text.replace(find_this, replace_with, 2).replace(replace_with, find_this, 1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO0Y8UO82xYH",
        "colab_type": "text"
      },
      "source": [
        "### Update the image size, we also add the update the test json files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUtpkuon2uAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "coco_instance_segmentation_fname = 'configs/_base_/datasets/coco_instance.py'\n",
        "fname = coco_instance_segmentation_fname\n",
        "with open(fname) as f:\n",
        "    s = f.read()\n",
        "    s = re.sub('img_scale=\\(.*?,.*?\\)',\n",
        "               'img_scale={}'.format(image_size), s)\n",
        "    s = replace_second_occurrence(s, 'annotations/instances_val2017.json', 'annotations/instances_test2017.json')\n",
        "    s = replace_second_occurrence(s, 'val2017/', 'test2017/')\n",
        "with open(fname, 'w') as f:\n",
        "    f.write(s)\n",
        "    \n",
        "coco_detection_fname = 'configs/_base_/datasets/coco_detection.py'\n",
        "fname = coco_detection_fname\n",
        "with open(fname) as f:\n",
        "    s = f.read()\n",
        "    s = re.sub('img_scale=\\(.*?,.*?\\)',\n",
        "               'img_scale={}'.format(image_size), s)\n",
        "    s = replace_second_occurrence(s, 'annotations/instances_val2017.json', 'annotations/instances_test2017.json')\n",
        "    s = replace_second_occurrence(s, 'val2017/', 'test2017/')\n",
        "with open(fname, 'w') as f:\n",
        "    f.write(s)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zYLe0Bu24f5",
        "colab_type": "text"
      },
      "source": [
        "### Update the number of epochs and learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teoRTY0820Mo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_schedule_fname = 'configs/_base_/schedules/schedule_1x.py'\n",
        "lr = 0.02\n",
        "\n",
        "fname = base_schedule_fname\n",
        "with open(fname) as f:\n",
        "    s = f.read()\n",
        "    s = re.sub('total_epochs = \\d+',\n",
        "               'total_epochs = {}'.format(total_epochs), s)\n",
        "    s = re.sub('lr=\\d+.\\d+',\n",
        "               'lr={}'.format(lr), s)\n",
        "with open(fname, 'w') as f:\n",
        "    f.write(s)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Awh5fvaP2-h4",
        "colab_type": "text"
      },
      "source": [
        "### Add a pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iGD0cO728_R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79c47aa7-4c35-42b9-f5a5-f2dc06b3113f"
      },
      "source": [
        "# If you want to use a COCO pretrained model, you need a link to the model. \n",
        "# You replace the None in load_from with the link to the pretrained model. \n",
        "# We do not have a pretrained model for ResNet18 on COCO, \n",
        "# so do not update the load_from, leave it as None\n",
        "\n",
        "%%writefile configs/_base_/default_runtime.py\n",
        "checkpoint_config = dict(interval=1)\n",
        "# yapf:disable\n",
        "log_config = dict(\n",
        "    interval=50,\n",
        "    hooks=[\n",
        "        # dict(type='TextLoggerHook'),\n",
        "        # dict(type='TensorboardLoggerHook')\n",
        "    ])\n",
        "# yapf:enable\n",
        "dist_params = dict(backend='nccl')\n",
        "log_level = 'INFO'\n",
        "load_from = 'https://open-mmlab.s3.ap-northeast-2.amazonaws.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
        "resume_from = None\n",
        "workflow = [('train', 1)]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting configs/_base_/default_runtime.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybuDp8g43Pa-",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Training Time!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGDODRjA3Sh1",
        "colab_type": "text"
      },
      "source": [
        "### Time to train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hqi6-vKJ3Kz0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6866a620-66b5-4516-df9d-40b85f3e3cfc"
      },
      "source": [
        "!python tools/train.py {config_file}"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-07 16:45:08,442 - mmdet - INFO - Environment info:\n",
            "------------------------------------------------------------\n",
            "sys.platform: linux\n",
            "Python: 3.6.9 (default, Jul 17 2020, 12:50:27) [GCC 8.4.0]\n",
            "CUDA available: True\n",
            "CUDA_HOME: /usr/local/cuda\n",
            "NVCC: Cuda compilation tools, release 10.1, V10.1.243\n",
            "GPU 0: Tesla K80\n",
            "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "PyTorch: 1.6.0+cu101\n",
            "PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 10.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
            "\n",
            "TorchVision: 0.7.0+cu101\n",
            "OpenCV: 4.1.2\n",
            "MMCV: 1.1.1\n",
            "MMDetection: 2.4.0+f240bf9\n",
            "MMDetection Compiler: GCC 7.5\n",
            "MMDetection CUDA Compiler: 10.1\n",
            "------------------------------------------------------------\n",
            "\n",
            "2020-09-07 16:45:08,824 - mmdet - INFO - Distributed training: False\n",
            "2020-09-07 16:45:09,134 - mmdet - INFO - Config:\n",
            "model = dict(\n",
            "    type='FasterRCNN',\n",
            "    pretrained='torchvision://resnet50',\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        depth=50,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=True),\n",
            "        norm_eval=True,\n",
            "        style='pytorch'),\n",
            "    neck=dict(\n",
            "        type='FPN',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='StandardRoIHead',\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='SingleRoIExtractor',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32]),\n",
            "        bbox_head=dict(\n",
            "            type='Shared2FCBBoxHead',\n",
            "            in_channels=256,\n",
            "            fc_out_channels=1024,\n",
            "            roi_feat_size=7,\n",
            "            num_classes=1,\n",
            "            bbox_coder=dict(\n",
            "                type='DeltaXYWHBBoxCoder',\n",
            "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
            "            reg_class_agnostic=False,\n",
            "            loss_cls=dict(\n",
            "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
            "            loss_bbox=dict(type='L1Loss', loss_weight=1.0))))\n",
            "train_cfg = dict(\n",
            "    rpn=dict(\n",
            "        assigner=dict(\n",
            "            type='MaxIoUAssigner',\n",
            "            pos_iou_thr=0.7,\n",
            "            neg_iou_thr=0.3,\n",
            "            min_pos_iou=0.3,\n",
            "            match_low_quality=True,\n",
            "            ignore_iof_thr=-1),\n",
            "        sampler=dict(\n",
            "            type='RandomSampler',\n",
            "            num=256,\n",
            "            pos_fraction=0.5,\n",
            "            neg_pos_ub=-1,\n",
            "            add_gt_as_proposals=False),\n",
            "        allowed_border=-1,\n",
            "        pos_weight=-1,\n",
            "        debug=False),\n",
            "    rpn_proposal=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=2000,\n",
            "        nms_post=1000,\n",
            "        max_num=1000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=dict(\n",
            "        assigner=dict(\n",
            "            type='MaxIoUAssigner',\n",
            "            pos_iou_thr=0.5,\n",
            "            neg_iou_thr=0.5,\n",
            "            min_pos_iou=0.5,\n",
            "            match_low_quality=False,\n",
            "            ignore_iof_thr=-1),\n",
            "        sampler=dict(\n",
            "            type='RandomSampler',\n",
            "            num=512,\n",
            "            pos_fraction=0.25,\n",
            "            neg_pos_ub=-1,\n",
            "            add_gt_as_proposals=True),\n",
            "        pos_weight=-1,\n",
            "        debug=False))\n",
            "test_cfg = dict(\n",
            "    rpn=dict(\n",
            "        nms_across_levels=False,\n",
            "        nms_pre=1000,\n",
            "        nms_post=1000,\n",
            "        max_num=1000,\n",
            "        nms_thr=0.7,\n",
            "        min_bbox_size=0),\n",
            "    rcnn=dict(\n",
            "        score_thr=0.05,\n",
            "        nms=dict(type='nms', iou_threshold=0.5),\n",
            "        max_per_img=100))\n",
            "dataset_type = 'CocoDataset'\n",
            "data_root = 'data/coco/'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
            "    dict(type='RandomFlip', flip_ratio=0.5),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=(1333, 800),\n",
            "        flip=False,\n",
            "        transforms=[\n",
            "            dict(type='Resize', keep_ratio=True),\n",
            "            dict(type='RandomFlip'),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=2,\n",
            "    workers_per_gpu=2,\n",
            "    train=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file='data/coco/annotations/instances_train2017.json',\n",
            "        img_prefix='data/coco/train2017/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
            "            dict(type='RandomFlip', flip_ratio=0.5),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file='data/coco/annotations/instances_val2017.json',\n",
            "        img_prefix='data/coco/val2017/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(1333, 800),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file='data/coco/annotations/instances_test2017.json',\n",
            "        img_prefix='data/coco/test2017/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(1333, 800),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]))\n",
            "evaluation = dict(interval=1, metric='bbox')\n",
            "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=None)\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='linear',\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=0.001,\n",
            "    step=[8, 11])\n",
            "total_epochs = 12\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(interval=50, hooks=[])\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = 'https://open-mmlab.s3.ap-northeast-2.amazonaws.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "work_dir = './work_dirs/faster_rcnn_r50_fpn_1x_coco'\n",
            "gpu_ids = range(0, 1)\n",
            "\n",
            "2020-09-07 16:45:09,739 - mmdet - INFO - load model from: torchvision://resnet50\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n",
            "100% 97.8M/97.8M [00:00<00:00, 165MB/s]\n",
            "2020-09-07 16:45:10,793 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "2020-09-07 16:45:19,151 - mmdet - INFO - load checkpoint from https://open-mmlab.s3.ap-northeast-2.amazonaws.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
            "Downloading: \"https://open-mmlab.s3.ap-northeast-2.amazonaws.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\" to /root/.cache/torch/hub/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
            "100% 160M/160M [00:15<00:00, 10.6MB/s]\n",
            "2020-09-07 16:45:36,321 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([2, 1024]).\n",
            "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([4, 1024]).\n",
            "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([4]).\n",
            "2020-09-07 16:45:36,324 - mmdet - INFO - Start running, host: root@c9332dc0af07, work_dir: /content/mmdetection/work_dirs/faster_rcnn_r50_fpn_1x_coco\n",
            "2020-09-07 16:45:36,325 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs\n",
            "2020-09-07 16:45:50,221 - mmdet - INFO - Saving checkpoint at 1 epochs\n",
            "[                                                  ] 0/5, elapsed: 0s, ETA:/content/mmdetection/mmdet/core/post_processing/bbox_nms.py:52: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  labels = valid_mask.nonzero()[:, 1]\n",
            "[>>] 5/5, 3.3 task/s, elapsed: 2s, ETA:     0s2020-09-07 16:45:53,184 - mmdet - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.03s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\n",
            "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.047\n",
            "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.002\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.051\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.420\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.420\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.420\n",
            "2020-09-07 16:46:06,852 - mmdet - INFO - Saving checkpoint at 2 epochs\n",
            "[>>] 5/5, 3.3 task/s, elapsed: 2s, ETA:     0s2020-09-07 16:46:09,605 - mmdet - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.00s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.048\n",
            "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.101\n",
            "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.026\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.138\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.220\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.220\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.220\n",
            "2020-09-07 16:46:23,278 - mmdet - INFO - Saving checkpoint at 3 epochs\n",
            "[>>] 5/5, 3.3 task/s, elapsed: 2s, ETA:     0s2020-09-07 16:46:26,044 - mmdet - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.00s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.255\n",
            "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.560\n",
            "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.417\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.480\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.480\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.480\n",
            "2020-09-07 16:46:39,691 - mmdet - INFO - Saving checkpoint at 4 epochs\n",
            "[>>] 5/5, 3.3 task/s, elapsed: 2s, ETA:     0s2020-09-07 16:46:42,446 - mmdet - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n",
            "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.967\n",
            "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.208\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.497\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.520\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.520\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.520\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.520\n",
            "2020-09-07 16:46:56,079 - mmdet - INFO - Saving checkpoint at 5 epochs\n",
            "[>>] 5/5, 3.3 task/s, elapsed: 2s, ETA:     0s2020-09-07 16:46:58,888 - mmdet - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.565\n",
            "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 1.000\n",
            "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.683\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.565\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.600\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.600\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.600\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.600\n",
            "2020-09-07 16:47:12,477 - mmdet - INFO - Saving checkpoint at 6 epochs\n",
            "[>>] 5/5, 3.3 task/s, elapsed: 2s, ETA:     0s2020-09-07 16:47:15,243 - mmdet - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.615\n",
            "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 1.000\n",
            "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.762\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.615\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.640\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.640\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.640\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.640\n",
            "2020-09-07 16:47:28,846 - mmdet - INFO - Saving checkpoint at 7 epochs\n",
            "[>>] 5/5, 3.3 task/s, elapsed: 2s, ETA:     0s2020-09-07 16:47:31,535 - mmdet - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.00s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.00s).\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.618\n",
            "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 1.000\n",
            "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.618\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.640\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.640\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.640\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.640\n",
            "2020-09-07 16:47:45,151 - mmdet - INFO - Saving checkpoint at 8 epochs\n",
            "[>>] 5/5, 3.3 task/s, elapsed: 2s, ETA:     0s2020-09-07 16:47:47,953 - mmdet - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.509\n",
            "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 1.000\n",
            "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.183\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.509\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.560\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.560\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.560\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.560\n",
            "2020-09-07 16:48:01,577 - mmdet - INFO - Saving checkpoint at 9 epochs\n",
            "[>>] 5/5, 3.3 task/s, elapsed: 2s, ETA:     0s2020-09-07 16:48:04,373 - mmdet - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.509\n",
            "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 1.000\n",
            "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.183\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.509\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.560\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.560\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.560\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.560\n",
            "2020-09-07 16:48:17,999 - mmdet - INFO - Saving checkpoint at 10 epochs\n",
            "[>>] 5/5, 3.4 task/s, elapsed: 1s, ETA:     0s2020-09-07 16:48:20,788 - mmdet - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476\n",
            "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 1.000\n",
            "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.183\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.517\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.540\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.540\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.540\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.540\n",
            "2020-09-07 16:48:34,381 - mmdet - INFO - Saving checkpoint at 11 epochs\n",
            "[>>] 5/5, 3.3 task/s, elapsed: 2s, ETA:     0s2020-09-07 16:48:37,201 - mmdet - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n",
            "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 1.000\n",
            "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.183\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.492\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.520\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.520\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.520\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.520\n",
            "2020-09-07 16:48:50,794 - mmdet - INFO - Saving checkpoint at 12 epochs\n",
            "[>>] 5/5, 3.2 task/s, elapsed: 2s, ETA:     0s2020-09-07 16:48:53,644 - mmdet - INFO - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n",
            "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 1.000\n",
            "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.183\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.492\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.520\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.520\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.520\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.520\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q-azNlR33SI",
        "colab_type": "text"
      },
      "source": [
        "### Confirmed the trained model exists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzfhzDoe3VUp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "abc61a7c-2f5e-4b5a-b7cf-cc21b50b1431"
      },
      "source": [
        "# Confirm the latest trained model exists\n",
        "work_dir = \"work_dirs/\" + selected_model\n",
        "checkpoint_file = os.path.join(work_dir, \"latest.pth\")\n",
        "assert os.path.isfile(\n",
        "    checkpoint_file), '`{}` not exist'.format(checkpoint_file)\n",
        "checkpoint_file = os.path.abspath(checkpoint_file)\n",
        "checkpoint_file"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/mmdetection/work_dirs/faster_rcnn_r50_fpn_1x_coco/latest.pth'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RlZigZu36yD",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the results of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeW7zOuq4C5h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "3cb2daa6-f1e0-4602-cfca-c57fa6102975"
      },
      "source": [
        "# Evaluate your model by bbox for bounding box\n",
        "!python tools/test.py {config_file} {checkpoint_file} --eval bbox"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[                                                  ] 0/5, elapsed: 0s, ETA:/content/mmdetection/mmdet/core/post_processing/bbox_nms.py:52: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  labels = valid_mask.nonzero()[:, 1]\n",
            "[>>] 5/5, 2.7 task/s, elapsed: 2s, ETA:     0s\n",
            "Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.672\n",
            "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 1.000\n",
            "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.723\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.400\n",
            "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.775\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.700\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.700\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.700\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.400\n",
            "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.775\n",
            "{'bbox_mAP': 0.672, 'bbox_mAP_50': 1.0, 'bbox_mAP_75': 0.723, 'bbox_mAP_s': -1.0, 'bbox_mAP_m': 0.4, 'bbox_mAP_l': 0.775, 'bbox_mAP_copypaste': '0.672 1.000 0.723 -1.000 0.400 0.775'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZNZT54w4VmK",
        "colab_type": "text"
      },
      "source": [
        "### Step 4: Time to test the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nb0MCz642qx",
        "colab_type": "text"
      },
      "source": [
        "### Setup library and functions for testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4VRmjL24X7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
        "\n",
        "# Collect the list of images to test. You can update this list with the files you want to test. It can be a single image or multiple images\n",
        "files_for_test = glob.glob(\"data/coco/test2017/*.jpg\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaLTzV6_47Gn",
        "colab_type": "text"
      },
      "source": [
        "### Create a helper function to test our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOchB1O84m1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We create a helper method that takes an image and returns its prediction. We save a copy of the image appending result at the beginning of the original image name\n",
        "from IPython.display import Image\n",
        "def show_result(img_path, score_thr):\n",
        "  \n",
        "  # build the model from a config file and a checkpoint file\n",
        "  model = init_detector(config_file, checkpoint_file, device='cuda:0')\n",
        "\n",
        "  img_result_path = 'result_' + img_path.split(\"/\")[-1]\n",
        "\n",
        "  print(\"Result: \", img_result_path)\n",
        "\n",
        "  result = inference_detector(model, img_path)\n",
        "  res2 = model.show_result(img_path, result,\n",
        "            score_thr=score_thr, thickness = 4, \n",
        "            bbox_color = \"green\",  \n",
        "            font_scale=1.0, \n",
        "            out_file=img_result_path, \n",
        "            text_color=\"green\"\n",
        "            )\n",
        "  \n",
        "  # Show the image with bbox overlays.\n",
        "  Image(filename=img_result_path) "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z99kSx6K5JZD",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug-2vXG9W2yd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSfhxDaL4oMg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "52d00ec0-b7dd-4310-e490-883d4695f8d1"
      },
      "source": [
        "# Testing the above method for only one image\n",
        "score_thr = 0.5 # Choose the threshold of the accuracy you want\n",
        "img = 'data/coco/test2017/27.jpg' # Location of the image\n",
        "show_result(img, score_thr) # Call the method passing in the necessary parameters"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result:  result_27.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/mmdetection/mmdet/core/post_processing/bbox_nms.py:52: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  labels = valid_mask.nonzero()[:, 1]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5dCeGBB5E6r",
        "colab_type": "text"
      },
      "source": [
        "### Test the prediction on the test models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8Nsqq2J4sV3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "98b4e2e3-0c7d-4d24-82f3-b00b9c984d45"
      },
      "source": [
        "# To test on images in a list\n",
        "score_thr = 0.5 # Choose accuracy threshold\n",
        "for file in files_for_test:\n",
        "  show_result(file, score_thr)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result:  result_29.jpg\n",
            "Result:  result_28.jpg\n",
            "Result:  result_27.jpg\n",
            "Result:  result_25.jpg\n",
            "Result:  result_26.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df6C-eLvaZNk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3a493861-3fd8-4a09-c1ac-3efac73b2f76"
      },
      "source": [
        "cd mmdetection/"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'mmdetection/'\n",
            "/content/mmdetection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS6UIiGLaSzY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5c51ba5-99e2-4eaf-adcd-7a4f10f69a0e"
      },
      "source": [
        "img = 'data/coco/val2017/20.jpg' # ENTER IMAGE HERE\n",
        "show_result(img, score_thr) # Call the method passing in the necessary parameters"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result:  result_20.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}